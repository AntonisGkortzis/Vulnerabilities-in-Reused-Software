{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICSR '19 - Gkortzis et al. - Data Collection\n",
    "\n",
    "This notebook describes and performs the following steps necessary to collect all data used in the study:\n",
    "\n",
    "1. [Download projects from GitHub](#download)\n",
    "2. [Compile and install Maven projects](#install)\n",
    "3. [Retrieve projects' dependencies](#dependencies)\n",
    "4. [Run Spotbugs](#spotbugs)\n",
    "5. [Extract metrics and create analysis dataset](#metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"download\"></a>\n",
    "## Download Projects from GitHub\n",
    "\n",
    "With a list of Github Maven repositories, the first step is to clone these reposirotories locally. This is the task that the github_downloader script performs. \n",
    "\n",
    "The execute_downloader requires three parameters:\n",
    "1. `credentials` : `String`. The github credentials in a specific format (`github_username:github_token`)\n",
    "2. `repository_list` : `Filepath`. The list of repositories to clone locally\n",
    "3. `download_directory` : `Directory`. The fullpath of the directory where the repositories will be cloned\n",
    "Additionally, there is an optional parameter: \n",
    "4. `Boolean`. That can be used to update (perform a git pull) on an already existing repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import github_downloader\n",
    "\n",
    "credentials = \"github_username:github_token\" # replace this value with your personal credentials\n",
    "repository_list = \"/home/agkortzis/git_repos/ICSR19/analysis/starred_github_maven_repositories_top300.txt\"\n",
    "download_directory = \"/media/agkortzis/Data/test_repos\" # replace this value\n",
    "\n",
    "github_downloader.execute_downloader(credentials, repository_list, download_directory)\n",
    "# github_downloader.execute_downloader(credentials, repoInputFile, repoStoreRoot, update_existing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install\"></a>\n",
    "## Compile and install Maven projects\n",
    "\n",
    "The next step after downloading the projects is to perform a maven install. This process will collect the projects dependencies and generate the `.jar` file. Both, the `.jar` file and the dependencies will be stored in the `.m2` directory under each project's direcoty. \n",
    "This `.m2` root directory is, by default, located under the users folder (`/home/user/.m2`).\n",
    "\n",
    "The `execute_mvn_install` requires one argument:\n",
    "1. `root_directory` : `Directory`. The full path of the directory in which all repositories (downloaded by the previous step) are located.\n",
    "\n",
    "Users can also define the following two optional parametes:\n",
    "2. `Boolean`. Perform a mvn clean on each repository before compiling it again, and\n",
    "3. `Datetime`. Checkout each repository to a specific date. Date shoud be formatted as `YYYY-MM-DD` (example `2018-12-25`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import maven_installer\n",
    "\n",
    "root_directory = f'/media/agkortzis/Data/maven_projects_old_versions/' # replace this value\n",
    "maven_installer.execute_mvn_install(root_directory)\n",
    "# maven_installer.execute_mvn_install(root_directory,True,'2018-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dependencies\"></a>\n",
    "## Retrieve project dependencies\n",
    "\n",
    "Having a local copy of each maven reporitory we proceed with retrieving their dependency tree. Each tree will be stored in a separate file (with `.trees` suffix) for further analysis as we describe on the next [step](#spotbugs). If a project consist of more than one modules, a seperate tree of each module will be stored in the `.trees` file.\n",
    "\n",
    "This step requires two parameters:\n",
    "1. `root_directory` : `Directory`. The full path of the directory that stores the repositories \n",
    "2. `output_directory` : `Directory`. The full path of the directory that will store the `.trees` files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dependency_extractor\n",
    "\n",
    "root_directory = f\"/media/agkortzis/Data/maven_projects_old_versions/\" # replace this value\n",
    "output_directory = \"/home/agkortzis/git_repos/ICSR19/analysis/data/test\" # replace this value\n",
    "\n",
    "dependency_extractor.execute(root_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"spotbugs\"></a>\n",
    "## Run SpotBugs\n",
    "\n",
    "With the installed projects, the next step is to run SpotBugs.\n",
    "For that, we use the `.trees` files, which contain the dependency tree for each module built for the project.\n",
    "\n",
    "Thus, for each project (i.e., each `.trees` files), the next sub-steps are:\n",
    "1. Parse the `.trees` file\n",
    "2. Ignore modules that are not Java source code (not `.jar` nor `.war`)\n",
    "3. For each remaining tree (i.e., for each `.jar`/`.war` module):\n",
    "  1. Select relevant dependencies (i.e., compile dependencies)\n",
    "  2. Verify if main package and dependencies are installed in the `.m2` local repository\n",
    "  3. Run SpotBugs for the set **[module] + [dependencies]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import maven\n",
    "import spotbugs\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "currentDT = datetime.datetime.now()\n",
    "print (\"Started at :: {}\".format(str(currentDT)))\n",
    "\n",
    "\n",
    "def run_spotbugs(file_project_trees, output_file):\n",
    "\n",
    "    trees = maven.get_compiled_modules(file_project_trees)\n",
    "    \n",
    "    if not trees:\n",
    "        logging.info(f'No modules to analyze: {file_project_trees}.')\n",
    "        return\n",
    "\n",
    "    pkg_paths = []\n",
    "    for t in trees:\n",
    "        pkg_paths.extend([a.artifact.get_m2_path() for a in t])\n",
    "        \n",
    "    pkg_paths = list(set(pkg_paths))\n",
    "    spotbugs.analyze_project(pkg_paths, output_file)\n",
    "\n",
    "\n",
    "path_to_data = os.path.abspath('../data')\n",
    "\n",
    "projects_tress = [f for f in os.listdir(path_to_data) if f.endswith('.trees')]\n",
    "\n",
    "for f in projects_tress:\n",
    "    filepath = path_to_data + os.path.sep + f\n",
    "    output_file = f'{os.path.splitext(filepath)[0]}.xml'\n",
    "    run_spotbugs(filepath, output_file)\n",
    "\n",
    "    \n",
    "currentDT = datetime.datetime.now()\n",
    "print (\"Finished at :: {}\".format(str(currentDT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"metrics\"></a>\n",
    "## Extract metrics and create analysis dataset\n",
    "\n",
    "*[Describe steps]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import maven as mvn\n",
    "import spotbugs as sb\n",
    "import sloc\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "currentDT = datetime.datetime.now()\n",
    "print (\"Started at :: {}\".format(str(currentDT)))\n",
    "\n",
    "\n",
    "def project_level_metrics(trees, spotbugs_xml):\n",
    "    modules = [m.artifact for m in trees]\n",
    "    dep_modules = [m.artifact for t in trees for m in t.deps if m.artifact not in modules]\n",
    "    dep_modules = list(set(dep_modules)) # remove duplicates\n",
    "    \n",
    "    # Collect classes from user code\n",
    "    project_classes = [c for m in modules for c in m.get_class_list()]\n",
    "    \n",
    "    # Collect classes from dependencies\n",
    "    dep_classes = [c for m in dep_modules for c in m.get_class_list()]\n",
    "    \n",
    "    # Collect SLOC info\n",
    "    classes_sloc = {}\n",
    "    for m in (modules + dep_modules):\n",
    "        classes_sloc.update(sloc.retrieve_SLOC(m.get_m2_path())[0])\n",
    "            \n",
    "    vdict = sb.collect_vulnerabilities(spotbugs_xml, {'uv': project_classes, 'dv': dep_classes})\n",
    "    \n",
    "    uv_classes = [sb.get_main_classname(b) for c in vdict['uv'] for r in c for b in r]\n",
    "    uv_classes = list(set(uv_classes))\n",
    "    \n",
    "    dv_classes = [sb.get_main_classname(b) for c in vdict['dv'] for r in c for b in r]\n",
    "    dv_classes = list(set(dv_classes))\n",
    "    \n",
    "    uv_count = [len(r) for c in vdict['uv'] for r in c]\n",
    "    dv_count = [len(r) for c in vdict['dv'] for r in c]\n",
    "    \n",
    "    u_sloc = sum([int(classes_sloc[c]) for c in sloc.get_roots(project_classes)])\n",
    "    d_sloc = sum([int(classes_sloc[c]) for c in sloc.get_roots(dep_classes)])\n",
    "    \n",
    "    uv_classes_sloc = sum([int(classes_sloc[c]) for c in sloc.get_roots(uv_classes)])\n",
    "    dv_classes_sloc = sum([int(classes_sloc[c]) for c in sloc.get_roots(dv_classes)])\n",
    "    \n",
    "    return [\n",
    "        len(project_classes),  # #u_classes   \n",
    "        len(dep_classes),      # #d_classes \n",
    "        len(uv_classes),       # #uv_classes \n",
    "        len(dv_classes),       # #dv_classes \n",
    "        u_sloc,                # #u_sloc \n",
    "        d_sloc,                # #d_sloc  \n",
    "        uv_classes_sloc ,      # #uv_classes_sloc \n",
    "        dv_classes_sloc        # #dv_classes_sloc \n",
    "    ] + uv_count + dv_count    # #uv_p1_r1 | #uv_p1_r2 ... | #dv_p3_r3 | #dv_p3_r4\n",
    "\n",
    "    \n",
    "def collect_sp_metrics(file_project_trees, output_file, append_to_file=True):\n",
    "\n",
    "    trees = mvn.get_compiled_modules(file_project_trees)\n",
    "    spotbugs_xml = f'{os.path.splitext(file_project_trees)[0]}.xml'\n",
    "    proj_name = os.path.basename(os.path.splitext(file_project_trees)[0])\n",
    "    \n",
    "    if not trees:\n",
    "        logging.warning(f'No modules to analyze: {file_project_trees}.')\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(spotbugs_xml):\n",
    "        logging.warning(f'SpotBugs XML not found: {spotbugs_xml}.')\n",
    "        return\n",
    "    \n",
    "    metrics = project_level_metrics(trees, spotbugs_xml)\n",
    "    \n",
    "    if append_to_file:\n",
    "        with open(output_file, 'a') as f:\n",
    "            f.write(','.join([proj_name] + [str(m) for m in metrics]) + os.linesep)\n",
    "    else:\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(','.join([proj_name] + [str(m) for m in metrics]) + os.linesep)\n",
    "            \n",
    "    logging.debug(','.join([proj_name] + [str(m) for m in metrics]) + os.linesep)\n",
    "\n",
    "            \n",
    "path_to_data = os.path.abspath('../data')\n",
    "projects_dataset = os.path.abspath('../projects-dataset.csv')\n",
    "metrics_header = ['#u_classes', '#d_classes', '#uv_classes', '#dv_classes', \n",
    "           '#u_sloc', '#d_sloc', '#uv_classes_sloc', '#dv_classes_sloc', \n",
    "           '#uv_p1_r1', '#uv_p1_r2', '#uv_p1_r3', '#uv_p1_r4', \n",
    "           '#uv_p2_r1', '#uv_p2_r2', '#uv_p2_r3', '#uv_p2_r4', \n",
    "           '#uv_p3_r1', '#uv_p3_r2', '#uv_p3_r3', '#uv_p3_r4', \n",
    "           '#dv_p1_r1', '#dv_p1_r2', '#dv_p1_r3', '#dv_p1_r4', \n",
    "           '#dv_p2_r1', '#dv_p2_r2', '#dv_p2_r3', '#dv_p2_r4', \n",
    "           '#dv_p3_r1', '#dv_p3_r2', '#dv_p3_r3', '#dv_p3_r4', ]\n",
    "\n",
    "with open(projects_dataset, 'w') as f:\n",
    "    f.write(','.join((['project'] + metrics_header)) + os.linesep)\n",
    "    \n",
    "for f in projects_tress:\n",
    "    filepath = path_to_data + os.path.sep + f\n",
    "    collect_sp_metrics(filepath, projects_dataset)\n",
    "\n",
    "\n",
    "currentDT = datetime.datetime.now()\n",
    "print (\"Finished at :: {}\".format(str(currentDT)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
